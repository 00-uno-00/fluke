{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "\n",
    "from fl_bench.data.datasets import Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = Datasets.MNIST(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mnist.train[0].shape == torch.Size([60000, 28, 28])\n",
    "assert mnist.train[1].shape == torch.Size([60000])\n",
    "assert mnist.test[0].shape == torch.Size([10000, 28, 28])\n",
    "assert mnist.test[1].shape == torch.Size([10000])\n",
    "assert mnist.num_classes == len(set(mnist.train[1].unique().tolist() + mnist.test[1].unique().tolist()))\n",
    "assert mnist.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist4d = Datasets.MNIST4D(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mnist4d.train[0].shape == torch.Size([60000, 1, 28, 28])\n",
    "assert mnist4d.train[1].shape == torch.Size([60000])\n",
    "assert mnist4d.test[0].shape == torch.Size([10000, 1, 28, 28])\n",
    "assert mnist4d.test[1].shape == torch.Size([10000])\n",
    "assert mnist4d.num_classes == len(set(mnist4d.train[1].unique().tolist() + mnist4d.test[1].unique().tolist()))\n",
    "assert mnist4d.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist = Datasets.EMNIST(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert emnist.train[0].shape == torch.Size([112800, 28, 28])\n",
    "assert emnist.train[1].shape == torch.Size([112800])\n",
    "assert emnist.test[0].shape == torch.Size([18800, 28, 28])\n",
    "assert emnist.test[1].shape == torch.Size([18800])\n",
    "assert emnist.num_classes == len(set(emnist.train[1].unique().tolist() + emnist.test[1].unique().tolist()))\n",
    "assert emnist.num_classes == 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn = Datasets.SVHN(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert svhn.train[0].shape == torch.Size([73257, 3, 32, 32])\n",
    "assert svhn.train[1].shape == torch.Size([73257])\n",
    "assert svhn.test[0].shape == torch.Size([26032, 3, 32, 32])\n",
    "assert svhn.test[1].shape == torch.Size([26032])\n",
    "assert svhn.num_classes == len(set(svhn.train[1].unique().tolist() + svhn.test[1].unique().tolist()))\n",
    "assert svhn.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = Datasets.CIFAR10(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cifar10.train[0].shape == torch.Size([50000, 3, 32, 32])\n",
    "assert cifar10.train[1].shape == torch.Size([50000])\n",
    "assert cifar10.test[0].shape == torch.Size([10000, 3, 32, 32])\n",
    "assert cifar10.test[1].shape == torch.Size([10000])\n",
    "assert cifar10.num_classes == len(set(cifar10.train[1].unique().tolist() + cifar10.test[1].unique().tolist()))\n",
    "assert cifar10.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100 = Datasets.CIFAR100(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cifar100.train[0].shape == torch.Size([50000, 3, 32, 32])\n",
    "assert cifar100.train[1].shape == torch.Size([50000])\n",
    "assert cifar100.test[0].shape == torch.Size([10000, 3, 32, 32])\n",
    "assert cifar100.test[1].shape == torch.Size([10000])\n",
    "assert cifar100.num_classes == len(set(cifar100.train[1].unique().tolist() + cifar100.test[1].unique().tolist()))\n",
    "assert cifar100.num_classes == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistm = Datasets.MNISTM(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mnistm.train[0].shape == torch.Size([60000, 3, 28, 28])\n",
    "assert mnistm.train[1].shape == torch.Size([60000])\n",
    "assert mnistm.test[0].shape == torch.Size([10000, 3, 28, 28])\n",
    "assert mnistm.test[1].shape == torch.Size([10000])\n",
    "assert mnistm.num_classes == len(set(mnistm.train[1].unique().tolist() + mnistm.test[1].unique().tolist()))\n",
    "assert mnistm.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiny Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_imagenet = Datasets.TINY_IMAGENET(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tiny_imagenet.train[0].shape == torch.Size([100000, 3, 64, 64])\n",
    "assert tiny_imagenet.train[1].shape == torch.Size([100000])\n",
    "assert tiny_imagenet.test[0].shape == torch.Size([10000, 3, 64, 64])\n",
    "assert tiny_imagenet.test[1].shape == torch.Size([10000])\n",
    "assert tiny_imagenet.num_classes == len(set(tiny_imagenet.train[1].unique().tolist() + tiny_imagenet.test[1].unique().tolist()))\n",
    "assert tiny_imagenet.num_classes == 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femnist = Datasets.FEMNIST(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(femnist[0]) == 3597 # Total number of clients\n",
    "assert len(femnist[1]) == 3597 # Total number of clients\n",
    "assert femnist[0][0].tensors[0].shape[1:] == torch.Size([1, 28, 28]) # image shape\n",
    "assert sum([femnist[0][i].tensors[1].shape[0] == femnist[0][i].tensors[0].shape[0] for i in range(len(femnist[0]))]) == len(femnist[0]) # number of labels matches number of images in each client\n",
    "\n",
    "assert femnist[1][0].tensors[0].shape[1:] == torch.Size([1, 28, 28]) # image shape\n",
    "assert sum([femnist[1][i].tensors[1].shape[0] == femnist[1][i].tensors[0].shape[0] for i in range(len(femnist[1]))]) == len(femnist[1]) # number of labels matches number of images in each client\n",
    "\n",
    "lbl_train = set.union(*[set(femnist[0][i].tensors[1].numpy()) for i in range(len(femnist[0]))])\n",
    "lbl_test = set.union(*[set(femnist[1][i].tensors[1].numpy()) for i in range(len(femnist[1]))])\n",
    "assert len(lbl_train | lbl_test) == 62 # Total number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake = Datasets.SHAKESPEARE(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(shake[0]) == 660\n",
    "assert len(shake[1]) == 660\n",
    "assert shake[0][0].tensors[0].shape[1:] == torch.Size([80]) # Shakespeare text\n",
    "assert shake[1][0].tensors[0].shape[1:] == torch.Size([80]) # Shakespeare text\n",
    "\n",
    "assert sum([shake[0][i].tensors[1].shape[0] == shake[0][i].tensors[0].shape[0] for i in range(len(shake[0]))]) == len(shake[0]) \n",
    "assert sum([shake[1][i].tensors[1].shape[0] == shake[1][i].tensors[0].shape[0] for i in range(len(shake[1]))]) == len(shake[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = Datasets.FASHION_MNIST(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fashion.train[0].shape == torch.Size([60000, 28, 28])\n",
    "assert fashion.train[1].shape == torch.Size([60000])\n",
    "assert fashion.test[0].shape == torch.Size([10000, 28, 28])\n",
    "assert fashion.test[1].shape == torch.Size([10000])\n",
    "assert fashion.num_classes == len(set(fashion.train[1].unique().tolist() + fashion.test[1].unique().tolist()))\n",
    "assert fashion.num_classes == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CINIC10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinic = Datasets.CINIC10(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cinic.train[0].shape == torch.Size([90000, 3, 32, 32])\n",
    "assert cinic.train[1].shape == torch.Size([90000])\n",
    "assert cinic.test[0].shape == torch.Size([90000, 3, 32, 32])\n",
    "assert cinic.test[1].shape == torch.Size([90000])\n",
    "assert cinic.num_classes == len(set(cinic.train[1].unique().tolist() + cinic.test[1].unique().tolist()))\n",
    "assert cinic.num_classes == 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
