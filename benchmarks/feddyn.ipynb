{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcebab41",
   "metadata": {},
   "source": [
    "# FEDDYN BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc758d",
   "metadata": {},
   "source": [
    "We try to reproduce the results of the paper [FEDERATED LEARNING BASED ON  DYNAMIC REGULARIZATION](https://arxiv.org/abs/2111.04263) on the MNIST dataset. The paper introduces a new algorithm called FedDyn, which is a Federated Averaging algorithm where a linear and quadratic penalty terms are added to the loss, whose minima is consistent with the global stationary point. The algorithm is tested on the MNIST dataset with [MNIST_2NN](../fluke/nets.py:549)(a 2-layer MLP first introduced with FedAvg, in our case it's hidden layers will respectively be 200 and 100). The paper shows that FedProx outperforms FedAvg in terms of convergence speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667dc0e9",
   "metadata": {},
   "source": [
    "## Setup of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cd1b0",
   "metadata": {},
   "source": [
    "### Loading and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data.datasets import Datasets\n",
    "dataset = Datasets.get(\"mnist\", path=\"../data\", channel_dim=1)  #by default we use the data folder that will be created upon the first run, \n",
    "                                                                #the get method will create another folder if the selected dataset is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\",\n",
    "                        client_split=0.1,\n",
    "                        sampling_perc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb72fbf",
   "metadata": {},
   "source": [
    "### Setting up the evaulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.evaluation import ClassificationEval, Evaluator\n",
    "from fluke import GlobalSettings\n",
    "\n",
    "evaluator = ClassificationEval(1,n_classes=dataset.num_classes)\n",
    "GlobalSettings().set_evaluator(evaluator)\n",
    "GlobalSettings().set_device(\"cuda\")\n",
    "GlobalSettings().set_seed(87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75fb8d9",
   "metadata": {},
   "source": [
    "### Setting hyperparameters and model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke import DDict\n",
    "from fluke import nets\n",
    "# We set up the hyperparameters according to the paper's description\n",
    "client_hp = DDict(\n",
    "    batch_size=50,\n",
    "    local_epochs=50,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    alpha=0.01,#overall best obtained from grid search \n",
    "    optimizer=DDict(\n",
    "      lr=0.1,\n",
    "      weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1)\n",
    ")\n",
    "\n",
    "alg_hp = DDict(\n",
    "    client = client_hp,\n",
    "    server=DDict(weighted=False),\n",
    "    model=\"MNIST_2NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b73c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms.feddyn import FedDyn\n",
    "algorithm = FedDyn(100, splitter, alg_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9bf56",
   "metadata": {},
   "source": [
    "### Setting up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.utils.log import Log\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e5530",
   "metadata": {},
   "source": [
    "## Running the experiment   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c2787",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.use_deterministic_algorithms(mode=True, warn_only=True)\n",
    "algorithm.run(100, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42086450",
   "metadata": {},
   "source": [
    "target 98.25~ ottenuto 92~ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
