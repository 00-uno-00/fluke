{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEDAVG BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to reproduce the results of the paper [Federated Optimization in Heterogeneous Networks](https://arxiv.org/abs/1812.06127) on the MNIST dataset. The paper introduces a new algorithm called FedProx, which is a Federated Averaging algorithm with a proximal term added to the loss function to encourage the local models to be close to each other. The algorithm is tested on the MNIST dataset with a [MNIST_LR](../fluke/nets.py:549)(a simple logistic regression model). The paper shows that FedProx outperforms FedAvg in terms of convergence speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data.datasets import Datasets\n",
    "dataset = Datasets.get(\"mnist\", path=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.evaluation import ClassificationEval, Evaluator\n",
    "from fluke import GlobalSettings\n",
    "\n",
    "evaluator = ClassificationEval(eval_every=1, n_classes=dataset.num_classes)\n",
    "GlobalSettings().set_evaluator(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the hyperparameters and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke import DDict\n",
    "\n",
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=50,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    mu=1,\n",
    "    optimizer=DDict(\n",
    "      lr=0.03),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1)\n",
    ")\n",
    "\n",
    "alg_hp = DDict(\n",
    "    client = client_hp,\n",
    "    server=DDict(weighted=True),\n",
    "    model=\"MNIST_LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms.fedprox import FedProx\n",
    "algorithm = FedProx(1000, splitter, alg_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.utils.log import Log\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.run(40, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
